{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display, Image\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from shutil import copy\n",
    "from Loaders import Importer\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from tqdm import tqdm\n",
    "from uncertainties import ufloat\n",
    "\n",
    "from src.utils import prepare_dfs, disp_general_around_thresh\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport src.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widgets for visual inspection of all 100 trained networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixed stats for all final training runs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realisations = 10\n",
    "n_slices = 100\n",
    "main_root = pathlib.Path(\"./00_demonstrations_data/100_CNNs\")\n",
    "hparams_sets = [\n",
    "    {'batch_size': 64,\n",
    "    'lr': 1e-4,\n",
    "    'perturb': True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dfs(hparams_sets, real_no=n_realisations, n_slices=n_slices, main_root=main_root)\n",
    "folder_names = [f\"bs={bs}_perturb={perturb}_lr={lr:.0e}\" for bs, lr, perturb in zip([h['batch_size'] for h in hparams_sets], [h['lr'] for h in hparams_sets], [h['perturb'] for h in hparams_sets])]\n",
    "possible_cols = hparams_sets[0]['df'].columns[2:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a38470dd51f41189cdc0a5ccee938f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='above', options=(True, False), value=True), Dropdown(description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(\n",
    "    disp_general_around_thresh,\n",
    "    hparam_sets=fixed(hparams_sets[0]),\n",
    "    # df=fixed(all_stats_df), \n",
    "    column_name=possible_cols, \n",
    "    above=[True, False], \n",
    "    head_number=fixed(20), \n",
    "    loc_in_head=(0, 19, 1),\n",
    "    thresh_proc=(0.0, 1.0, 0.01),\n",
    "    comp_axis_1=possible_cols, \n",
    "    comp_axis_2=possible_cols, \n",
    "    real_slice_no=fixed(\"10_100\"), \n",
    "    sig=(0.1, 5.0, 0.1),\n",
    "    shown_stat=['generalization', 'history', 'UMAP', 'PCA', 'CAMs'],\n",
    "    cam_ind=(0, 99, 1),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 64 | Perturb True | Learning Rate 0.0001 | Threshold (RMSE) = 0.2\n",
      "\n",
      "Well-generalizing models\n",
      "Percentage: 22.0% | Test clean accuracy: 0.947+/-0.019 | OOD Accuracy: 0.860+/-0.030 | RMSE: 0.153+/-0.031\n",
      "Poorly-generalizing models\n",
      "Percentage: 78.0% | Test clean accuracy: 0.970+/-0.023 | OOD Accuracy: 0.61+/-0.10 | RMSE: 0.41+/-0.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "clean_acc_thresh = 0\n",
    "lpips_thresh = 0.18\n",
    "rmse_thresh = 0.2\n",
    "chosen_col = 'RMSE'\n",
    "thresh = rmse_thresh\n",
    "\n",
    "for perturb in [True]:\n",
    "    d_tmp = {\n",
    "        'batch_size': batch_size,\n",
    "        'lr': lr,\n",
    "        'perturb': perturb,\n",
    "    }\n",
    "    df_found = None\n",
    "    for d in hparams_sets:\n",
    "        if all([d_tmp[k] == d[k] for k in d_tmp.keys()]):\n",
    "            df_found = d['df']\n",
    "            break\n",
    "    if df_found is None:\n",
    "        raise ValueError('Dataframe not found')\n",
    "\n",
    "    df_acc_constraint = df_found.where(df_found[\"Clean Accuracy\"] >= clean_acc_thresh).dropna()\n",
    "    df_generalizing = df_acc_constraint.where(df_acc_constraint[chosen_col] <= thresh).dropna()\n",
    "    df_not_generalizing = df_acc_constraint.where(df_acc_constraint[chosen_col] > thresh).dropna()\n",
    "    # print(df_generalizing['Accuracy'].max())\n",
    "    print(f\"Batch size {batch_size} | Perturb {perturb} | Learning Rate {lr} | Threshold ({chosen_col}) = {thresh}\\n\")\n",
    "    print(f\"Well-generalizing models\\nPercentage: {len(df_generalizing)/len(df_found)*100:.1f}% | Test clean accuracy: {ufloat(df_generalizing['Clean Accuracy'].mean(), df_generalizing['Clean Accuracy'].std())} | OOD Accuracy: {ufloat(df_generalizing['Accuracy'].mean(), df_generalizing['Accuracy'].std())} | {chosen_col}: {ufloat(df_generalizing[chosen_col].mean(), df_generalizing[chosen_col].std())}\")\n",
    "    print(f\"Poorly-generalizing models\\nPercentage: {len(df_not_generalizing)/len(df_found)*100:.1f}% | Test clean accuracy: {ufloat(df_not_generalizing['Clean Accuracy'].mean(), df_not_generalizing['Clean Accuracy'].std())} | OOD Accuracy: {ufloat(df_not_generalizing['Accuracy'].mean(), df_not_generalizing['Accuracy'].std())} | {chosen_col}: {ufloat(df_not_generalizing[chosen_col].mean(), df_not_generalizing[chosen_col].std())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
